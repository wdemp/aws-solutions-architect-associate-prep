This is a comprehensive review of the wrong answers that I got on test 4. This review will include the answers, why they're correct
and what could have been the reason behind them being wrong.



Question 1: You are hosting a web server on an EC2 Instance. With the number of requests consuming a large part of the CPU, 
the response performance for the application is getting degraded. Which of the following would help to alleviate the problem 
and provide a better response time?

Answer: Place a CloudFront distribution in front of the EC2 Instance.
Answer I chose: Place the EC2 instance behind the App Load balancer.
Reasoning according to Whizlabs: "Since there is a mention of only one EC2 instance, placing it behind the ELB 
would not make much sense, hence Options A & B are invalid."
Having it an autoscaling group with just one instnace would not make much sense
Cloudfront distribution would help to alleviate the load in the EC2 instance because of its edge location and cache feature




Question 3: A company is hosting a MySQL database in AWS using the AWS RDS service. To offload the reads, a Read Replica has been created and 
reports are run off the Read Replica database. But at certain times, the reports show stale data. 
What could be the possible reason behind this?

Real Answer: This is due to the replicate lag.

Whizlabs Reasoning: An AWS Whitepaper on the caveat for reading replicas is given below which must be taken into consideration
by architects. Read Replicas are seperate database instance that are replicated asychronously. As a result, they are subject to
replication lag and might be missing sme of the latest transactions. Application architects need to consider which queries
 have the tolerance to slightly state data. These queries can be executed on a Read Replica, while the rest should run on the
 primary node. Read Replicas may also not accept any write queries.


Answer I chose: The backup of the original database has not been set properly.
 My Reasoning: I clearly didn't read this that well. The words "at certain times, the reports show stale data" was a pretty dead
 giveaway. I need to read more carefully. 

Question 6: A company has set up its data layer in the Simple Storage Service. There are a number of requests which include read/write and updates to objects in an S3 bucket. 
Users sometimes complain that updates to an object are not being reflected. What could be the most likely reason for this?

My Answer I chose: Versioniong is not enabled for the bucket, so the newer version does not reflect the right data.
Reasoning: I asssumed versioning was the answer. The reason being that I saw the word "update" ; since this is S3 
updating is part of what versioning does. 

Real Answer: Updates made to the object usually take sometime to reflect. 
Whizlabs Explanation: Updates made to the objects in S3 follow an eventaul consistency model. Hence, for object updates there can
be a slight delay when an updated object is provided back to the user on the next request.

Question 8: A company planning to move to the AWS Cloud wants to leverage its existing Chef recipes for configuration management of its infrastructure. 
Which AWS service would be ideal to fulfill this requirement?

Answer I chose: AWS Elastic Beanstalk
Reasoning: I didn't have enough knowledge about AWS Opworks to figure out that it was the right answer.

Actaul Answer: AWS OpsWorks is a configuration management service that helps you to configure and operate applications in a cloud 
in a cloud enterprise by using Puppet or Chef. AWS OpsWorks Stacks and AWS OpsWorks for Chef Automate let you use Chef cookbooks 
and solutions for configuration management, while AWS OpsWorks for Puupet Enterprise lets you configure a Puppet Enterprise master 
server in AWS Puppet offers a set of tools for enforcing the desired starte of your infrastructure and automating on-demand
tasks. 

Question 10: A company offers its customers short-lived contests that require users to upload files in hopes of winning prizes.
These contests can last up to two weeks, with unknown uploads and the resulting file analysis can last up to three months. 
The company currently stores four weeks of data in an S3 bucket and now it needs an economic and scalable object storage solution to hold it's customer files.
The files will be accessed once and then deleted. What would be the best solution for the company in this scenario?

My Answer: Amazon Standard S3
Reasoning: I chose Standard S3 because in the scenario nothing at the time really stuck out as needng more.
In this case, giving less would have been a better option. The Infrequent Access is less than the Standard. 
Real Answer: S3 Infrequent Access.
Whizlabs Reasoning: Given the scenario, this data is going to be accessed a lot less; however when it needs to be accessed it needs 
to be quick.

Question 11: Question 11: You plan on hosting a web application consisting of a web server and a database server.
These servers are going to be hosted on different EC2 Instances in different subnets in a VPC. What should be used to ensure that the database server only allows 
traffic from the web server?
My Answer: Make use of VPC flow logs.
Reasoning: I thought that the Security groups had more control over more of the subnets security. This was clearly wrong and bad 
to out down. I need more work with security groups.

Whizlabs answer: Security groups can be used to control traffic into an EC2 instance.
**Interesting Note from Whizlabs: NACL is used when you want to deny the access for a particular IP address or the CIDR block
So, the main point here is that if the requirement allows traffic, then you can go wtih the Security group. If the requirement 
mentioned that is~ is denies traffic than you go with NACL.

Question 14: A company has a Redshift Cluster defined in AWS. The IT Operations team have ensured that both 
automated and manual snapshots are in place. Since the cluster is going to be run for a long duration of a couple of years, 
Reserved Instances have been purchased. There has been a recent concern on the cost, being incurred by the cluster.
Which step should be carried out to minimize the costs being incurred by the cluster?
My Answer: Choose to use Spot Instances instead of Reserved Instances
Reasoning: The question mentioned Spot and reserved Instances. In addition the question also mentioned that there was a cost 
concern. So since Spot Instance are cheaper I went with that. On top of that being wrong, teh question also states that 
the Instances need to be run for a couple of years. Reserved Instances are LITERALLY intended to run for a specific amount of
years. This is all stated in the contract prior to purchasing them.

Whizlabs answer: Delete the manual snapshots
Explanation: Whether they are automated or manually taken, Snapshots can be deleted or created at any time. Manual snapshots
are keot indefintely, even after you delete the cluster. You can specify the retention period when you create a manual snapshot
or you can change the retention period when you create a manual snapshot or you can change the retention period by modifying 
the snapshot. If you create a snapshot using the Amazon Redshift console, it defaults the snapshot retention period to 365 days.
Automated snapshots are automatically deleted within the period of at least 1 to 35 days(this is settings based) So if you want the Manual snapshots to be 
deleted you have to do it yourself.

Question 15: A website is hosted on two EC2 instances that sit behind an Elastic Load Balancer. The response time of the website has been slowed down 
dramatically, and customers are placing fewer orders due to the wait time. Troubleshooting showed that one of the EC2 instances has been failed and only one instance is running now.
What is the best course of action to prevent this from happening in the future?

My Answer: Change the instance size to the maximum available tio compensate for the failure

Reasoning:  I didn't fully grasp the question at the time. As I read it now, there were plenty of clues as to what the question
was asking. Due to the instance failing and the website lagging. Clearly a healh check needs to be performed; in addition
with the website lagging. Checking the ELB was another obvious clue. 

Actaul Answer: Configure the ELB to perform health checks on the EC2 instances and implement auto-scaling.

Whizlabs explanation: Using the ELB to perform health checks will determine whether or not to remove a non-performing 
or underperforming instance, and have the autoscaling group launch a new intance.

Question 16: A company currently hosts a lot of data on its On-premises location. 
It wants to start storing backups of this data on AWS. How could this be achieved in the most efficient way?

My answer: Create EBS Snapshots and store the data

Reasoning: I was thinking at the time that the Snapshots would be the best way to transfer the data to the new databse. 
However, upon reading this now the people in the scenario would have had to have had an AWS account prior. They wouldn't
have been able to use AWS EBS Snapshots. The Storage Gaetway Stored Volumes is designed for integration with data security
features between yout on-premise IT environment and the AWS storage infrastructure. 
Actual Answer: Make use of Storage Gateway Stored Volumes.
Whizlabs Explanation: AWS Storage Gateway connects to an on-premises software appliance with cloud based storage
to provide seasmles integration with data security features between your on-premises IT environment and the AWS
storage infrastructure. You can use the service tio store data in the AWS Cloud for scalable and cost effective that helps
to maintain data security. 
It has 2 types of configuration, cached volumes, and stored volumes.

Our requirement is to start storing backups of the on-premise data to AWS.
In cached volumes, you store you data in S3 and retain a copy of frequently accessed data subsets locally. It means that we are
not storing the backups on S3 but the actual primary data itself.
But in stored mode, your primary data is stored locally and and your entire dataset is available for low latency access while
access while asychronously backed up to AWS S3.

Question 18: Currently, you have a set of Lambda functions which have business logic embedded in them. 
You want customers to have the ability to call these functions via HTTPS. 
How could this be achieved?
My Answer: Add EC2 Instances with an API server installed. Integrate the server with AWS Lambada functions.
Reasoning: I really didn't understand the question at the time


